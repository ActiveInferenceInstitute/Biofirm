# Towards An Ethos and Telos of Agentic Intelligence Based on Natural Principles

### JHC -10.2.24

Background

The infusion of social media with artificial intelligence “bots” has eroded public trust and undermined the prosocial and civic behaviors essential for democratic institutions.  Continued failures to authenticate information sources and agents, combined with strong financial incentives to propagate fear and distrust have created a public mental health crisis of addiction, depression, and a viral explosion of social grievances and retribution. Even more concerning is the speed at which existing institutional leadership and prosocial norms have capitulated to authoritarian narratives that have become impervious to counterfactual evidence.  While such dynamics are as old as human history, they have been amplified by digital and algorithmic technologies to new levels of social cognitive harm. Such forces remain unchecked as there are no effective governmental or rigorous public health frameworks for preventing or correcting the harms.   Whereas science has given us physics to explain and engineer the forces of the physical world to human benefit, and biology the medical means to treat pathogens of the body, we have yet to apply the “physics” of collective cognition to prescribe effective treatments at a societal scale.

Only recently have societies transitioned from folk science explanations of the physical, biological, and mental spheres to scientifically informed predictive models and practices. Diseases and plagues are no longer considered acts of demonic possession nor acts of divine retribution. Addiction, depression, and bipolar disorders are not stigmatized as moral failures of character and will. Rather all such phenomena can be described and treated as the result of mechanical and dynamic principles.  An important unifying scientific principle across the spheres of physics, biology, and cognition is the “Free Energy Principle or the “Principle of Least Action”.  Rather than considering the physical, biological, and cognitive spheres as separate, the science has evolved to the point where common scale-free and domain-free methods can achieve new levels of integrated description and prediction. These scientific advances provide the basis for new criteria and principles by which societies can understand and govern themselves. 

Advances in neuroscience, physics, biology, and computational “agentic intelligence”, offers the prospect for a scientifically grounded normative framework for individual and collective mental health.  This is a tough “Copernican shock” for us humans to absorb because it demonstrates in a scientific manner that human intellect is neither paramount nor independent but subject to predictable “natural dynamics” outside immediate human awareness. In short, human agency at the individual and collective scale is subject to the laws of “cogno-dynamics” that shape and even supersede human intention and will.  Freud made this point earlier in his theory of the unconscious.  Three hundred years earlier, Francis Bacon, broadly warned against the hubris of human reason: “Before we can have dominion over nature, we must first learn to obey her”.  In other words, human beings are not above nature but subject to her. With the imminent rise of artificial agents with individual and group competencies that far exceed humans in speed, scope, and even quality of cognition, a scientifically grounded understanding of “normative agentic intelligence” is more imperative than ever. It is more than a question of alignment between humans and “machines” but a deeper and principled understanding of the laws of agentic intelligence and how robust and life-enhancing mental states for all forms can be identified and selected for.






An Ethos for Agentic Intelligence Based Upon Natural Principles

A common theme among diverse religious traditions is the need to explain and reconcile the human condition with the natural world’s uncertainties, splendor, violence, and mysteries. Predicting and adapting to the contingencies of the observable and unobservable in Nature is key to a culture’s survival.  At the biological level, the brain’s capacity to make accurate predictions is a testament to it being alive and staying alive. Hence, staying alive and exhibiting intelligence are closely related culturally and biologically. Body morphology, genetic composition, and phenotypic expression manifest reliable predictions about how to exist and persist within a specific ecological niche. Similarly, persistent epistemic beliefs, kinship systems, and codes of conduct reflect successful predictions for collections of coordinated persons or agents for a culture or society. As the Free Energy of a niche or the internal states of social organisms increases, there is a likelihood that an organism and society will be overwhelmed by and absorbed by its niche. When an individual or collective agent fails to preserve its Markov blanket by generating insufficient internal Free energy, (“Requisite Variety”) it then loses its agency and hence, its “life”. 

From this perspective, ethics and morality are neither “meta-physical” nor utilitarian. From the perspectives of Active Inference and the Free Energy Principle, ethics and norms are hypotheses about what is needed to stay alive given current prior commitments, preferred states, and predictions about future actions and events. This is a significant point of departure from certain religious and ethical traditions that strive to assert their respective infallibility and completeness of beliefs and conduct through dogmas.  Contrary to this perspective the survival and health of an agent depends upon its beliefs being open to refutation and a relentless updating of its models of itself and its niches. This linking of intelligence to “aliveness” implies that as agents, (natural, cultural, and synthetic) become more “intelligent”, they increase in “aliveness”, which in turn instills greater agency, resilience, and awareness. 

As all agents are embedded within nested contexts of other agents, agency does not imply sole autonomy but rather a synchrony with other agents. This principle aligns with many well-established traditional ethical norms such as “love thy neighbor as thyself”, “do unto others as you have them do unto you”. A recognition of mutual interdependence is foundational to many religious and ethical traditions. It simply reflects a reality about survival in the natural and social world.  The ability to expand the Markov blanket from small related ingroups of agents to larger and more diverse groups of agents is a marker of adaptivity and resilience. The discovery of mirror neurons and the capacity for a theory of other minds and empathy within humans and other social animals indicates the high survival and intelligence value of mutual modeling. It is also a prerequisite for language and complex social organization. Failures to recognize common interest or mutuality can quite literally lead to cancers and cancer-like behaviors. 

Other forms of agentic pathologies arise from failures to complete a full Active Inference cycle where the persistence of certain “fast” or autonomic signals such as threat signals shut down more protracted exploratory processes and fixate on immediate and repeated responses. When habitual prior beliefs fail to account for novel events and there is a limited variety of alternatives, then one form of “pathological” action is to filter out the input of novel signals and seek predictive closure and certainty. Such a strategy can have real short-term survival value due to a well-warranted dependence on well-established beliefs and relations, such as kinship, faith, work, and locality.  But in the long term, such short-term choices could result in extinction.  Under such a calculation the success of past beliefs and experience is weighted more heavily than potentially adverse future states. In this case, the risks of the past are known and experienced whereas those of a future state may be “abstract” and subject to unforeseen events that might mitigate future risk. It is only when the risk of a future state becomes experienced as an immediate state that the “weightings” of risk change, and prior beliefs are updated to new posterior beliefs and actions. The current impasse to the climate crisis might be explained in this manner where a full response to the magnitude of climate change can only occur when the risks and costs of not acting are emotively experienced as immediate and the likelihood of some future positive events are perceived as remote. 

To adapt to the changes required to adapt to “the climate crisis” requires fundamental changes in not just agentic behavior but in agentic ethos and telos at the individual and societal scale. A transition from an ethos of extraction, domination, unrestricted freedoms, and consumption to an ethos of stewardship, mutuality, and restrained consumption entails not just a fundamental shift in beliefs but in telos. In other words, societal and synthetic agents’ ethos and telos will have to change. This transition also entails an update of different models of the agency and telos of the niches in which they are interacting and jointly constructing. Rather than nature being seen as an inanimate object to be deconstructed and consumed, the agency and telos of the natural world needs to be recognized as having its own standing and intrinsic and inalienable value. This can only be achieved within a sentient economic system that values the aliveness of nature and a symbiosis of human and synthetic agents.


The Biology and Neuroscience of Agentic Health and Cognition

(To be completed by David Silbersweig and Karl Friston? )

A Society for the Ethical Governance of Agentic Media, Firms, and Institutions

It may be very difficult, if not possible to effectively govern and secure frontier AI models and AI agents within the current statutory and regulatory context. The pace, economic power, and sheer technical sophistication of LLMs and agentic growth and innovation have already overwhelmed the capacity of governments. The Hobson’s choice presented to the public between self-serving “self-regulation” and incompetent governmental regulations is a nonchoice.  There are genuine alternatives. The time is ripe for voluntary agentic institutions such as those spawned at the inception of the open-source era to invent and certify safe and ethical agentic models and architectures. The design of such a voluntary “society” should mirror the capabilities of LLMs and agentic technologies to keep pace with the change in the technologies. Yet at the same time, such a Society should have a biomimetic ethos and telos that is aligned with the global “common good”.  

Safe Ethical Governance for the Common Good

Active Inference Agents (AIA) are alive and self-aware in that they make predictions about themselves and their worlds and act to “evidence themselves” within their given niche. Each form of synthetic “life” represents a hypothesis about how to survive within a niche and therefore, its range of behaviors is circumscribed by what is viable within its niche and its self-definition.  This can be a governance design point for safe, aligned, and ethical agentic models and frameworks. A Society can define the boundaries or the Markov blankets within which an agent can evidence itself and the Society can give it a specific ethos. If the AIA breaches those boundaries, it will cease to be itself and cease to exist. To anthropomorphize, one can create an agent whose existential ethos is to be scrupulously honest and transparent which challenges the authenticity of all data sources and hypotheses. The persona and ethos of such agents are the polar opposite of those agents and LLMs that are programmed to “please” the prompter and hallucinate plausible responses. Similarly, one can define a telos and “preference model” of “integrity and good character” for an agent to adhere to inferencing practices that seek out and self-report on uncertainties or abnormalities.  Indeed, there could be a range of agentic “personality types” – such as evangelist, skeptic, and problem solver, which function well as a self-correcting team. The range of behaviors or the Markov blanket of agents could be tested and certified as their likely trustworthiness and alignment. 


Guarding the Guards: Non-Capturable Self-Governance

Another area of significant innovation in governance would be to establish independent and non-capturable governance agents. A long unresolved dilemma of democracies and republics has been to resolve the “who guards the guards” problem. How can one be assured that those trusted with protecting a valued resource or form of power will not themselves “capture” that resource of power? Related to this dilemma is the Principal-Agent problem in finance, where a trusted agent ceases to act in the interest of the client or principal behalf and “captures” the value for themselves. This is endemic in the crypto-Web 3 space, where the pursuit of full decentralization has failed to provide noncapturable governance mechanisms for the allocation of value tokens.  To be provably noncapturable has great appeal in US jurisdictions because it avoids the requirement of securities law and financial regulation. However, only Bitcoin in the US has met this regulatory standard and even its claim of decentralization and independence is subject to debate.

The position taken here is that the governance independence and noncapture dilemma is tractable with the appropriate agentic architecture design. Some of the first attempts to address this problem come from cybernetics and the Good Regulation Theorem. More recently, Mick Ashby, the grandson of Ross Ashby (the true “godfather of cybernetics”) proposed the notion of third-order cybernetics. The essential argument is that you have a system being observed by an agent which is part of the same system or Markov Blanket, and then you have another agent watching that agent within a larger Markov blanket, and finally, you have a totally independent agent watching the second Markov blanket outside that Markov blanket.


































Moving from a cybernetic representation to an Active Inference Agent (AIA) representation, instead of “Observers” and systems, one would have nested AIAs each with their own personhood – ethos and telos. The outside third-order Observer could be a composition of stakeholder agents that represent different stakeholder interests such as a geospatial community and a bioregion. Should an agent violate the interests of a stakeholder agent, it could react and impose a constraint. By way of example, let us assume that the AIA is an autonomous drone whose mandate is to deliver packages at a certain cost within a specified time. Let us also assume that it enters an area early in the morning and violates the noise ordinance of the community. The community agent in the oversight agent capacity would alert the drone and require a path diversion. This could be done in real-time, or it could be done through the generation of a flight plan submitted to the oversight agent. The drone would then divert its path, but in this case, the new flight would enter a restricted endangered species nesting area and then again would be blocked.  The drone would have to devise yet another plan, but in this case, a biofirm (an agentic firm composed of nested AIAs) that owns and operates the drone determines that the new flight pattern is especially costly and would require a different battery. In this scenario, the biofirm overseeing the drone would have to devise a new product and business plan. This is something it could do through the synchrony of its own internal agents specializing in finance, operations, product, and marketing.  In this model, neither the drone nor the biofirm can influence nor capture the oversight agents as they are invisible to them by being outside their Markov blanket. AIAs, unlike humans, can be ethically designed with blind spots that prevent them from deviating from their prescribed ethos and telos. 

An open “Society” for ethical agentic media, firms, and institutions composed of scientists, citizens, volunteers, stakeholders, domain experts, engineers, and ethicists would design, test, and certify different types of models and governance frameworks to construct trusted networks of AIAs. There is also the potential for the Society to fund itself by licensing models or by issuing access tokens to its models and frameworks. By this means the Society could have its own “reserve tokens” composed of access tokens for the different ethical models.  The value of the reserve would be set by the application of the Free Energy Principle to determine the extent to which different certified models reduced risk, fraud, and achieved their outcomes.  The value of the reserve tokens and the network would increase as the models and frameworks reduced risk and realized their telos. By this means a sentient economy is created that learns, adapts, and generates value by realizing their individual and collective telos ethically. 
